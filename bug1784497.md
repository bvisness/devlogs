# Element segments (bug 1784497)

Ryan is concerned about the overhead of always storing init expressions, now that tables can store more than just indexes. The funny thing is...you can already make tables of externref in the core spec. Do we just not support that?

In any case, it's a reasonable concern, since it will be very common to have tables initialized by nothing but function indexes. And, beyond that, I think it could be common to have tables initialized by other types of indexes too?

The element segment encoding explicitly leaves space for this possibility, and indexes are all u32. So I think it's not crazy to reflect this indexes-or-initializers encoding difference in implementation too.

Ok, seems like we are possibly out of spec compliance right now anyway. We don't appear to have provisions for element segments with non-null externref values, but this should be possible today by importing globals and then doing global.get.

Ok, investigation complete. Only Chrome actually supports global.get in element segments; Firefox and Safari do not. wabt also does not. These all seem to explicitly require either ref.func or ref.null, which excludes global.get _and_ [number].const. I mean, I don't see any use for t.const in element segments because none of ref.func, ref.null, or global.get actually pop a value from the stack - but we'll need to add that support so we can do more meaningful initialization of structs and arrays.

I assume we'll be able to leverage our constant expression interpreter for all of this, although I don't know the details.
In particular I have no idea what the module-time storage of a struct.new would be? I suppose at compile time we just save the init expressions and run them on instantiation? But that seems like it would possibly slow down instantiation? I have no idea.
No duh of course they have to run during instantiation, global.get is a constant instruction, and globals come from imports, ergo this is not that weird and we just interpret constant expressions at instantiation time.

We have a weird situation here with how we store the data. Expanding beyond simple ref.func and ref.null will require us to actually interpret expressions at instantiation time like you'd expect. However, today, we actually interpret the expressions at compile time and save the indexes. Changing this will suddenly defer work to instantiation time that wasn't there before. I fear this may be a problem.

I suppose it may not be so bad, if we merely need to process a stream of bytes and the indices are all in predictable locations. But if this does turn out to be a problem - what are our options?

We could:

- Decode and store element expressions, then optimistically attempt to fill a vector with function indices (including special null indices). If this succeeds and we never encounter any instructions other than ref.func and ref.null, we can ditch the expressions completely and store indices again.
- Store both indices and expressions, and at compile time, convert any expressions to indices if they use simple instructions. This could save on evaluation time at instantiation time, but seems dumb because we can no longer do a simple index copy?

The best decision here hinges primarily on the data representation of tables (does it store bare func indices?) and how slow it actually is to evaluate init expressions when instantiating.


Okay, Monday. I talked with Ryan about this and here's how we're going to proceed.

1. Generalize element segments for spec compliance. This primarily means supporting global.get of a const global as a constant expression. This will already require us to significantly shake up our element segment code.
2. Add GC stuff to element segments. This will require us to implement a new type of storage for passive element segments to store the results of reference values after instantiation, because segment initialization happens on instantation, not on table.init or array.new_elem. This can hopefully just be a mozilla vector of anyref values (the internal kind of anyref).

I don't really know what the latter will entail, but the former is reasonable. Ryan thinks we should store two types of data in element segments, a vector of indices and a blob of bytecode. When we encounter the index encoding, we can just use the index vector. When we encounter the bytecode encoding, we can optimistically parse it as indices (w/ nulls), but upon encountering non-literal instructions (like global.get), we rewind and re-parse the section as bytecode. This optimistic decoding could be done in a second patch.

So a more concise view of the work might be:

1. Generalize element segments for full core spec compliance (funcref and externref tables, global.get and ? t.const ?)
  1.1. Trash the interleaved index/expression code, implement true bytecode storage and interpretation and index-only storage. Make it work.
  1.2. Implement optimistic bytecode -> index parsing to save memory and instantiation costs.
2. Implement GC stuff (details TODO)

Part 1.1 is already working well. Just need to patch up serialization stuff, since that seems to be the only case that's failing.

Hey that was easy. On to part 1.2.

lol nope, I forgot to run _all_ the wasm tests, and now there are problems. Although I think they might just be from changing the error message? No, there are other problems:

[x] wasm/binary.js
[x] wasm/ref-types/ref-func.js
[x] wasm/spec/spec/bulk.wast.js
[x] wasm/spec/spec/table_init.wast.js

Oh god, if table.init allows you to offset a particular distance into the element segment...how do we do that efficiently? We would currently need to parse all the expressions up until the index we care about, which would be wasting a ton of work. I'll need to rethink this (and also look at the implementation of table.init, which must be wildly wrong right now.)

Ok, I've been editing the implementation of table.init - it's just Instance::initElems. But am I just ignoring the source offset?

Yep.

Ugghgghgh

(Editorial note: I decided to store an extra vector of expression offsets, so we can just jump straight to a particular expression. It's...maybe fine.)

Ok, after some stupid shenanigans it is working again. Why does the spec allow you to do table.init with an out-of-bounds source offset as long as you init with zero items? Nonsense design. Out of bounds indices should always be invalid even if you're not going to copy anything.

All the tests pass! Finally, can ship this patch to Ryan.


Ok, time to start on the optimistic index storage. Seems like it shouldn't be too bad, but we'll see.

This actually turned out to be a little funky because ref.func is not treated as "literal" by DecodeConstantExpression. I thought it was, but it's not. "Literal" values also can't store non-null anyrefs (which is reasonable). This means that we don't immediately have a way to get function indices out of DecodeConstantExpression at all.

I ran this by Ryan and he thinks the optimistic parse is probably just not even important. The index encoding exists and is more efficient and more common. So I guess 1.2 is off the menu for now. It's not that big a deal; we can relatively easily reintroduce it later if need be.

This means I can remove NullElemIndex! Small win.


Finally things are passing try. Can move on and implement the InstanceElemSegment.

I wonder if it would be better to implement InstanceElemSegment with our current featureset, get it working, and then extend it to GC instructions? Seems plausible.

I also wonder if it is a problem to create an intermediate InstanceElemSegment when doing a workflow like instantiateStreaming. We could probably dump the refs straight into table memory instead of an intermediate vector. But it also probably doesn't matter very much aside from some temporary memory use.

Well actually, InstanceElemSegments need only exist for passive segments. Active segments wouldn't need it (although it may be convenient to use it). The elem.drop instruction can free the InstanceElemSegment.

Actually, it seems that active element segments persist after instantiation and can be used in table.init again. So we should just have an InstanceElemSegment for them too.

Er, wait...does this work? The spec test doesn't actually show the use of a table.init before elem.drop of an active segment. At least not this particular test.

Ok that was a fun tangent but I think I understand what we need to do with element segments now. Only passive segments can be used with table.init, KIND OF. Active and declarative segments are dropped during instantiation (literally the same semantics as elem.drop). This means we only need to allocate storage for passive segments at instantiation time. HOWEVER, since elem.drop semantically just sets the length of the element segment to zero, (table.init $elems 0 0 0) is _always valid_ for any type of element segment (as long as the types check out). This is dumb.

Anyway, with all the semantic nonsense sorted, I can now figure out how to actually implement this. Currently wasm::Instance has a `passiveElemSegments_` which is a vector of ElemSegment. This will need to be

uh what was I writing

I took a break there to discuss the spec further and ended up submitting a PR to the spec repo. Now that that's out of the way, back to actual element segment work...

So, we only need a runtime representation for passive segments. This is in line with how things work today. That said, the code for evaluating element segments will be significantly more complex than today and will certainly need to be shared across all types of element segments.

Declarative segments can be completely excluded from this work, because they are (semantically) dropped on instantiation. Their element expressions are never executed, so no need to worry about making useless allocations or anything.

The runtime representation for passive segments can basically become `Vector<AnyRef>`. This will make `table.init` simpler since we should literally just be able to do a bounds check and `table.fillAnyRef`. Of course, the logic currently in `Instance::initElems` will have to shift slightly to allow filling a vector for passive segments. Seems reasonable though.


I am back from my week away!

Time to get back to element segment stuff. Luckily I think I still remember pretty well what I have to do...this dev diary helps.

I think it's time to flesh out the work for "part 2". Maybe something like:

2.1 Implement InstanceElemSegment for existing ref types / expressions
2.2 Add GC constant instructions

So for 2.1, this means changing the type of `passiveElemSegments_`, and then fixing compile errors until it works :P

Some of these compile errors are hard to fix. I don't really know what data types to use, Maybe is giving me trouble, it's yelling about copy constructors...bleh. It used to be easy; we could just check for nullptrs. But we don't have a nice ! operator for vectors so here I am.

I don't need Maybe; zero vectors are fine because dropping an elem segment clears the length to zero anyway.

So now the potentially tricky thing is just unifying active and passive segment evaluation. Right now active segments funnel through initElems, but we need the ability to evaluate a segment to a Vector<AnyRef> instead of directly applying it to a table. The most obvious way, in my mind, is to use a Vector<AnyRef> (InstanceElemSegment) for both active and passive segments - however, it's not clear to me that we actually want to create AnyRefs for every single function index along the way. That seems bad for the function-table case.

I could do some kind of "iterator", or pass in a lambda perhaps?

There are three types of value we can try to store: null, funcref, and anyref.

Hm, the iterator approach seems maybe unnecessary since the expression-decoding approach currently gets anyrefs for all functions anyway. But I do think a lot of modules will want to use the index encoding anyway, and it would be a shame to lose that...

In the index case, we still only have function indices and can usually avoid an AnyRef. We do have to deal with imported functions, but the JSFunctions for these have already been created when they were exported. We can extract the code pointer and use that instead of creating an AnyRef. However, you can still store funcrefs in tables of non-function type, in which case we do create AnyRef. I suspect this is uncommon.

In the expression case, we currently use AnyRef for everything since it's the result type produced by LitVal. The use of LitVal is new code from me, so it's not a good comparison against the status quo. Previously we extracted indices from the expression stream, so all element segments would bypass AnyRef.

Perhaps we could thread a code pointer through LitVal in order to achieve a similar result, but this seems like a shame. I'm still not sure of the cost of using an AnyRef anyway...how much does it actually touch the GC?


Had conversations with Iain and Ryan about this issue yesterday and otherwise didn't really make any progress. Iain confirmed my hunch that we don't want to suddenly start allocating JSFunctions for every single wasm function, especially if most will immediately be garbage. However, talking to Ryan revealed that we already do create JSFunctions a lot more often than I originally thought.

Basically, the internal representation of a funcref is always a JSFunction (wrapped in an AnyRef). This has been true since we shipped reference types. This means that ALL uses of ref.func or table.get create (and cache) a JSFunction. This was kind of shocking to me. Within function tables, I believe we simply store an (instance pointer, code pointer) pair (called FunctionTableElem). A call_indirect can presumably use this info directly. However, a (call_ref (table.get)) does not; it creates a JSFunction and apparently caches it somewhere.

I feel like this is not necessary, and Ryan thinks we could change it, but it would take a fair amount of plumbing work in the compilers to do so because we'd be passing two pointers around instead of just one. Also, funcrefs can be stored in structs and arrays, and with multithreaded applications in mind, we definitely do not want any "tearing" when these are updated. So a one-pointer representation seems to still be important.

In any case, Ryan thinks we can just fast-track active segments with the index encoding. He thinks this will be far more common anyway.


Ok, after a bunch of confusing programming and changing how I was abstracting things, and figuring out how to add template specializations, I finally have it building. Tests are failing now; this is fine, I expected this. Let's work through the failures:

[x] wasm/passive-segs-boundary.js
[x] wasm/passive-segs-nonboundary.js
[x] wasm/passive-segs-partial-table.js
[x] wasm/tables.js
[x] wasm/ref-types/ref-func.js
[x] wasm/ref-types/tables-multiple.js
[x] wasm/spec/function-references/br_on_non_null.wast.js
[x] wasm/spec/function-references/br_on_null.wast.js
[x] wasm/spec/function-references/ref_as_non_null.wast.js
[x] wasm/spec/function-references/ref_func.wast.js
[x] wasm/spec/spec/bulk.wast.js
[x] wasm/spec/spec/ref_func.wast.js
[x] wasm/spec/spec/table_copy.wast.js
[x] wasm/spec/spec/table_init.wast.js

Well...that's a few cases we're failing. It's also just hard-crashing, so that's fun. Debugger!

Ok this is stupid. Specializing SafelyInitialized for AnyRef to be AnyRef::invalid() is causing GC barrier stuff to incorrectly think those are _valid_ AnyRefs. The issue is that some GC barrier code assumes that non-null is valid and can therefore do some stuff to get a store buffer, I dunno. In any case, non-null is _not_ valid; it's the pointer 0xffffffff, and this is giving me a bad access.

Do I specialize HeapPtr<AnyRef> instead to change the barrier stuff? Or do I change the specialization for SafelyInitialized to return nullptrs instead? That would be...strange, maybe.

Oh, we already have a specialization for the barrier methods on AnyRef. I can respect ::invalid() here.

Huh. I could have just called AnyRef::null() for SafelyInitialized instead of AnyRef::invalid(). Not sure which is better. If I do null, then I don't have to modify the barrier stuff. But maybe this is reasonable too.

Tests are passing, anyway. All of them, now! Just had to fix a few bounds check / length zero / null pointer types of bugs.

Ok, so now I've implemented InstanceElemSegment. Now I think perhaps I just have to add the GC constant expressions, and it will Just Work? Maybe?

Other stuff to check before I wrap up all this work:

[x] Look for places where table.setFuncRef is called and check if nulls are being handled correctly. Is there a way to avoid this pitfall in the future?


As part of his multi-memory work, Ryan seems to have done a patch that touches a lot of element segment stuff. Time for a messy rebase...

Actually, this seems fine. It just moved Module::initSegments to Instace::initSegments. Should be able to figure out what I did and re-apply it.

I'm now getting errors that I swear I should have gotten before. I removed reference counting from ModuleElemSegment because they're no longer shared between modules and instances; I am now crawling through and (correctly?) handling the change to inline storage. Interestingly, I guess this means that the segments don't need to be heap-allocated any more...? I can maybe change the logic that creates and initializes these segments. I forget where it is, but it currently uses `js_new<ModuleElemSegment>()`.

Well, I might have to change it anyway because I'm now getting constructor issues. Wahoo.

That involved a lot of changes, which I think is a good thing. Anyway, it builds now and tests are happy.

It really is pretty wild how much C++ obscures the way data is actually stored and managed.

Rebase complete!


...do we already support all the GC instructions here? Time to write some tests.

ha ha tests don't work because of that stupid test-suppression problem again now I get to fix those yay

Ah, crap. I think the text format doesn't yet like all these new constant instructions, even though our code might already be happy with it. Time to go dive into wasm-tools again.

Hm, it may just be that the text format only allows you to omit `(item)` in element segments when you provide "one instruction". I am providing folded instructions, which from a textual perspective sure look like "one", but I'm unclear on that. In any case, wrapping my structs with `item` seems to have now punted the problem to compilation, which seems better.

I mean, maybe better. I'm really not sure how we're getting "empty stack" errors here. Maybe wasm-tools is not in fact handling this correctly.

Never mind, we're fine, it's just that array.new_elem takes a couple args itself.

Well damn I think it works. Rad! Should definitely test it a bit more thoroughly, but hey, this is pretty solid.


Whoa...I hit an `unrecognized opcode` error when trying to make a test module. What is that about? fb 20...oh, that's i31.new. Maybe that patch hasn't actually landed yet. Will skip for now.

Everything seems to be working well. Feels nice. Gonna ship this out for review.

---

Shame on me for not keeping up a dev diary for this. Rebasing has gone to hell and I have a lot of tests to fix, and after doing robotics and traveling to Montreal I no longer have any idea where I was.

Wait tests are fine? Actually? wat

There were tests that were bad before...now they're fine...it is a mystery.

Ok well whatever, tests are passing, great. There is however one try failure, with compacting GC specifically: https://treeherder.mozilla.org/jobs?repo=try&revision=2b25731c0e9472b97ea4cfad7abec776e55fec67&selectedTaskRun=a_re78a2T_Cdk6ZfNvVv6g.0

Unfortunately it's just exiting with code -11. No errors. Probably just some kind of mysterious bad access after a compacting GC occurs?

OH that was what I was seeing in my console when I booted up my computer again 😅 I can run the compacting GC locally and the same errors manifest.

Running this command:

JS_GC_ZEAL=IncrementalMultipleSlices ./mach jit-test wasm --enable-parallel-marking --jitflags=debug

These are all probably manifestations of the same underlying problem, but here are the specific test failures:

[x] wasm/passive-segs-boundary.js
[x] wasm/passive-segs-nonboundary.js
[x] wasm/passive-segs-partial-table.js
[x] wasm/ref-types/ref-func.js
[x] wasm/spec/spec/bulk.wast.js
[x] wasm/spec/spec/table_copy.wast.js
[x] wasm/spec/spec/table_init.wast.js

yay I did the trace and now the no more bug

---

Back to element segments! Ryan has reviewed both patches and I need to fix them up for landing.

Very routine stuff so far, but this first patch was already reviewed once before. There was one obviously missing null check...no idea how that snuck through before. The tests that exercise it have been there for a year.

I suspect I never properly ran tests on the first commit somehow. The null check became irrelevant when moving to InstanceElemSegment.

Ryan pointed out a nice simplification from the separation of module and instance element segments. We no longer need random access to module element segments; the only use cases for them are active or declarative segments, which either require a complete linear scan or no access at all.

Ok, not bad at all to patch those up. Submitting a hopefully final try run!

---

Oh no. Oh no oh no. I messed up a rebase and now only have one commit instead of two. Oh _no_.

I am creating a tag at my current commit for reference and then reverting to an old one. I have to go back through all the previous comments and changes again and port my changes back over. God dammit.

The tag is bug1784497-conjoined.

I can check out specific files from that tag using:

git checkout tags/bug1784497-conjoined <filename>

Oh no it gets worse. I pushed the second commit's stuff to the first commit on Phabricator on Friday last week. I need to roll back to the versions that were on Phabricator and work forward again from there. Arghhhhhh

Specifically, diff 759502 (https://phabricator.services.mozilla.com/D182121?id=759502) on the first patch is bad and must be reverted.

I might need to dig more through reflog to actually find the changes I made. Some of this stuff was clearly lost.

Ok, commit 1396cdb9076ee seems to have the stuff I needed. It's clear to me where the rebase went wrong. Hopefully I can reuse those two refs as my two patches again and get this sorted.

Correct patch 1 commit: 1396cdb9076ee
Hopefully correct patch 2 commit: aa81a539d75cb
Amended patch 2 commit: c10861cae1f53

The amended patch 2 commit does the thing where we remove random access from ModuleElemSegment. It also converts the new iterator things to templates. These are good changes that I believe should only affect patch 2. (Basically, these are my final changes to patch 2 per Ryan's feedback.)

It seems like cherry-picking an amend commit on top of the original commit can do some weird stuff. I had to forcibly check out some other code from the conjoined tag to fix WasmInstance.cpp. Will need to manually review the diff here, again. Sigh. At least the tests are passing.

---

Landed :D
